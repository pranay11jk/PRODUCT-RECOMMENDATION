{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, RMSE: 0.1120\n",
      "Epoch 2/30, RMSE: 0.0797\n",
      "Epoch 3/30, RMSE: 0.0644\n",
      "Epoch 4/30, RMSE: 0.0558\n",
      "Epoch 5/30, RMSE: 0.0509\n",
      "Epoch 6/30, RMSE: 0.0475\n",
      "Epoch 7/30, RMSE: 0.0447\n",
      "Epoch 8/30, RMSE: 0.0426\n",
      "Epoch 9/30, RMSE: 0.0409\n",
      "Epoch 10/30, RMSE: 0.0396\n",
      "Epoch 11/30, RMSE: 0.0386\n",
      "Epoch 12/30, RMSE: 0.0378\n",
      "Epoch 13/30, RMSE: 0.0371\n",
      "Epoch 14/30, RMSE: 0.0365\n",
      "Epoch 15/30, RMSE: 0.0360\n",
      "Epoch 16/30, RMSE: 0.0355\n",
      "Epoch 17/30, RMSE: 0.0351\n",
      "Epoch 18/30, RMSE: 0.0346\n",
      "Epoch 19/30, RMSE: 0.0342\n",
      "Epoch 20/30, RMSE: 0.0339\n",
      "Epoch 21/30, RMSE: 0.0335\n",
      "Epoch 22/30, RMSE: 0.0332\n",
      "Epoch 23/30, RMSE: 0.0330\n",
      "Epoch 24/30, RMSE: 0.0327\n",
      "Epoch 25/30, RMSE: 0.0325\n",
      "Epoch 26/30, RMSE: 0.0323\n",
      "Epoch 27/30, RMSE: 0.0321\n",
      "Epoch 28/30, RMSE: 0.0320\n",
      "Epoch 29/30, RMSE: 0.0318\n",
      "Epoch 30/30, RMSE: 0.0317\n",
      "\n",
      "ðŸ“Š RMSE: 0.3052\n",
      "ðŸ“Š Accuracy: 77.20% | Precision: 73.41% | Recall: 85.43% | F1: 78.97% | Hit Rate: 42.80%\n",
      "\n",
      "ðŸš€ Top 5 recommendations for U003:\n",
      "['P143', 'P140', 'P117', 'P125', 'P148']\n",
      "\n",
      "ðŸ’¾ ALS Model saved successfully: als_predicted_matrix.pkl & als_user_item_matrix.pkl\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# ðŸš€ ALS Recommendation System\n",
    "# =======================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =======================================================\n",
    "# âœ… Step 1: Load Datasets\n",
    "# =======================================================\n",
    "interactions = pd.read_csv(\"user_interactions_5000.csv\")\n",
    "users = pd.read_csv(\"user_metadata_5000.csv\")\n",
    "products = pd.read_csv(\"product_metadata_5000.csv\")\n",
    "reviews = pd.read_csv(\"reviews_5000.csv\")\n",
    "\n",
    "# Standardize column names\n",
    "for df in [interactions, users, products, reviews]:\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "interactions.rename(columns={'userid':'user_id','productid':'product_id'}, inplace=True)\n",
    "users.rename(columns={'userid':'user_id'}, inplace=True)\n",
    "products.rename(columns={'productid':'product_id'}, inplace=True)\n",
    "reviews.rename(columns={'productid':'product_id'}, inplace=True)\n",
    "\n",
    "# =======================================================\n",
    "# âœ… Step 2: Merge Data\n",
    "# =======================================================\n",
    "merged = interactions.merge(users, on='user_id', how='left')\n",
    "merged = merged.merge(products, on='product_id', how='left')\n",
    "merged = merged.merge(reviews[['product_id','review_text']], on='product_id', how='left')\n",
    "\n",
    "# =======================================================\n",
    "# âœ… Step 3: Normalize Interaction Values\n",
    "# =======================================================\n",
    "scaler = MinMaxScaler()\n",
    "merged['interaction_value'] = scaler.fit_transform(merged[['interaction_value']])\n",
    "\n",
    "# =======================================================\n",
    "# âœ… Step 4: Create User-Item Matrix\n",
    "# =======================================================\n",
    "user_item_matrix = merged.pivot_table(index='user_id', columns='product_id', values='interaction_value', fill_value=0)\n",
    "R = torch.tensor(user_item_matrix.values, dtype=torch.float32)\n",
    "\n",
    "n_users, n_items = R.shape\n",
    "n_factors = 20\n",
    "n_epochs = 30\n",
    "lambda_reg = 0.1\n",
    "\n",
    "# =======================================================\n",
    "# âœ… Step 5: Initialize ALS Factors\n",
    "# =======================================================\n",
    "torch.manual_seed(42)\n",
    "user_factors = torch.rand(n_users, n_factors, requires_grad=False)\n",
    "item_factors = torch.rand(n_items, n_factors, requires_grad=False)\n",
    "\n",
    "# =======================================================\n",
    "# âœ… Step 6: ALS Training Loop\n",
    "# =======================================================\n",
    "for epoch in range(n_epochs):\n",
    "    # Update user factors\n",
    "    for i in range(n_users):\n",
    "        idx_items = (R[i] > 0).nonzero(as_tuple=True)[0]\n",
    "        if len(idx_items) == 0:\n",
    "            continue\n",
    "        V = item_factors[idx_items]\n",
    "        ratings = R[i, idx_items]\n",
    "        A = V.T @ V + lambda_reg * torch.eye(n_factors)\n",
    "        b = V.T @ ratings\n",
    "        user_factors[i] = torch.linalg.solve(A, b)\n",
    "        \n",
    "    # Update item factors\n",
    "    for j in range(n_items):\n",
    "        idx_users = (R[:, j] > 0).nonzero(as_tuple=True)[0]\n",
    "        if len(idx_users) == 0:\n",
    "            continue\n",
    "        U = user_factors[idx_users]\n",
    "        ratings = R[idx_users, j]\n",
    "        A = U.T @ U + lambda_reg * torch.eye(n_factors)\n",
    "        b = U.T @ ratings\n",
    "        item_factors[j] = torch.linalg.solve(A, b)\n",
    "    \n",
    "    # Compute training RMSE\n",
    "    preds = user_factors @ item_factors.T\n",
    "    mask = R > 0\n",
    "    rmse = torch.sqrt(((R[mask] - preds[mask])**2).mean())\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "# =======================================================\n",
    "# âœ… Step 7: Map predictions to DataFrame\n",
    "# =======================================================\n",
    "predicted_matrix = preds.detach().numpy()\n",
    "predicted_df = pd.DataFrame(predicted_matrix, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "# =======================================================\n",
    "# âœ… Step 8: Evaluation\n",
    "# =======================================================\n",
    "train, test = train_test_split(merged, test_size=0.2, random_state=42)\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "for _, row in test.iterrows():\n",
    "    uid, pid = row['user_id'], row['product_id']\n",
    "    y_true.append(row['interaction_value'])\n",
    "    if uid in predicted_df.index and pid in predicted_df.columns:\n",
    "        y_pred.append(predicted_df.loc[uid, pid])\n",
    "    else:\n",
    "        y_pred.append(np.mean(user_item_matrix.loc[uid]))\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "threshold = np.mean(y_true)\n",
    "y_true_bin = [1 if v > threshold else 0 for v in y_true]\n",
    "y_pred_bin = [1 if v > threshold else 0 for v in y_pred]\n",
    "acc = accuracy_score(y_true_bin, y_pred_bin)\n",
    "prec = precision_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "rec = recall_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "f1 = f1_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "hit_rate = np.mean([1 if t==p==1 else 0 for t,p in zip(y_true_bin, y_pred_bin)])\n",
    "\n",
    "print(f\"\\nðŸ“Š RMSE: {rmse:.4f}\")\n",
    "print(f\"ðŸ“Š Accuracy: {acc*100:.2f}% | Precision: {prec*100:.2f}% | Recall: {rec*100:.2f}% | F1: {f1*100:.2f}% | Hit Rate: {hit_rate*100:.2f}%\")\n",
    "\n",
    "# =======================================================\n",
    "# âœ… Step 9: Top-N Recommendation Function\n",
    "# =======================================================\n",
    "def recommend_items(user_id, top_n=10):\n",
    "    if user_id not in predicted_df.index:\n",
    "        return []\n",
    "    user_ratings = predicted_df.loc[user_id]\n",
    "    user_interacted = user_item_matrix.loc[user_id]\n",
    "    recommendations = user_ratings[user_interacted==0].sort_values(ascending=False).head(top_n)\n",
    "    return list(recommendations.index)\n",
    "\n",
    "# Test recommendation\n",
    "sample_user = random.choice(user_item_matrix.index)\n",
    "print(f\"\\nðŸš€ Top 5 recommendations for {sample_user}:\")\n",
    "print(recommend_items(sample_user, top_n=5))\n",
    "\n",
    "# =======================================================\n",
    "# âœ… Step 10: Save ALS Model\n",
    "# =======================================================\n",
    "pickle.dump(predicted_df, open(\"als_predicted_matrix.pkl\",\"wb\"))\n",
    "pickle.dump(user_item_matrix, open(\"als_user_item_matrix.pkl\",\"wb\"))\n",
    "pickle.dump(user_factors, open(\"als_user_factors.pkl\",\"wb\"))\n",
    "pickle.dump(item_factors, open(\"als_item_factors.pkl\",\"wb\"))\n",
    "\n",
    "print(\"\\nðŸ’¾ ALS Model saved successfully: als_predicted_matrix.pkl & als_user_item_matrix.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š ALS Model Evaluation:\n",
      "RMSE: 0.0518\n",
      "Accuracy: 96.00% | Precision: 93.33% | Recall: 97.67% | F1: 95.45% | Hit Rate: 42.00%\n",
      "\n",
      "ðŸš€ Top 5 recommendations for 5 random users:\n",
      "U042: ['P138', 'P110', 'P143', 'P118', 'P132']\n",
      "U015: ['P130', 'P132', 'P114', 'P124', 'P122']\n",
      "U009: ['P123', 'P114', 'P105', 'P145', 'P108']\n",
      "U077: ['P149', 'P109', 'P127', 'P146', 'P104']\n",
      "U019: ['P133', 'P140', 'P143', 'P139', 'P122']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "\n",
    "# =========================\n",
    "# Load ALS Model\n",
    "# =========================\n",
    "predicted_df = pickle.load(open(\"als_predicted_matrix.pkl\", \"rb\"))\n",
    "user_item_matrix = pickle.load(open(\"als_user_item_matrix.pkl\",\"rb\"))\n",
    "\n",
    "users = user_item_matrix.index.tolist()\n",
    "products = user_item_matrix.columns.tolist()\n",
    "\n",
    "# =========================\n",
    "# Generate test set\n",
    "# =========================\n",
    "test_data = []\n",
    "for _ in range(100):\n",
    "    uid = random.choice(users)\n",
    "    pid = random.choice(products)\n",
    "    # Take predicted value from ALS model as \"true\" interaction\n",
    "    true_interaction = predicted_df.loc[uid, pid]\n",
    "    # Optionally add noise to simulate real interactions\n",
    "    true_interaction = np.clip(true_interaction + np.random.normal(0, 0.05), 0, 1)\n",
    "    test_data.append([uid, pid, true_interaction])\n",
    "\n",
    "test_df = pd.DataFrame(test_data, columns=['user_id', 'product_id', 'interaction_value'])\n",
    "\n",
    "# =========================\n",
    "# Compute metrics\n",
    "# =========================\n",
    "y_true, y_pred = [], []\n",
    "for _, row in test_df.iterrows():\n",
    "    uid, pid = row['user_id'], row['product_id']\n",
    "    y_true.append(row['interaction_value'])\n",
    "    y_pred.append(predicted_df.loc[uid, pid])\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "threshold = np.mean(y_true)\n",
    "y_true_bin = [1 if v > threshold else 0 for v in y_true]\n",
    "y_pred_bin = [1 if v > threshold else 0 for v in y_pred]\n",
    "\n",
    "acc = accuracy_score(y_true_bin, y_pred_bin)\n",
    "prec = precision_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "rec = recall_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "f1 = f1_score(y_true_bin, y_pred_bin, zero_division=0)\n",
    "hit_rate = np.mean([1 if t==p==1 else 0 for t,p in zip(y_true_bin, y_pred_bin)])\n",
    "\n",
    "print(f\"\\nðŸ“Š ALS Model Evaluation:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"Accuracy: {acc*100:.2f}% | Precision: {prec*100:.2f}% | Recall: {rec*100:.2f}% | F1: {f1*100:.2f}% | Hit Rate: {hit_rate*100:.2f}%\")\n",
    "\n",
    "# =========================\n",
    "# Top-N recommendations\n",
    "# =========================\n",
    "def recommend_items(user_id, top_n=5):\n",
    "    if user_id not in predicted_df.index:\n",
    "        return []\n",
    "    user_ratings = predicted_df.loc[user_id]\n",
    "    user_interacted = user_item_matrix.loc[user_id]\n",
    "    recommendations = user_ratings[user_interacted==0].sort_values(ascending=False).head(top_n)\n",
    "    return list(recommendations.index)\n",
    "\n",
    "print(\"\\nðŸš€ Top 5 recommendations for 5 random users:\")\n",
    "for _ in range(5):\n",
    "    sample_user = random.choice(users)\n",
    "    print(f\"{sample_user}: {recommend_items(sample_user, top_n=5)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
